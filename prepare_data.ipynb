{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/childeden/miniconda3/envs/tryal/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from data.dataset import KuzushijiMNIST, get_subset, get_dataset, statstic_info\n",
    "from utils.seed import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample num: 60000, num_classes: 10, class_sample_num: [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "trials = 5\n",
    "request_rate = 0.2\n",
    "val_rate = 0.2\n",
    "\n",
    "prepared_data_save_path_template = './runs/prepared_data/%s/trial_%s/'\n",
    "dataset_name = 'mnist'\n",
    "\n",
    "raw_train_set, raw_test_set = get_dataset(dataset_name)\n",
    "num_classes = len(raw_train_set.classes)\n",
    "raw_train_set_stat = statstic_info(raw_train_set)\n",
    "print(f'Train sample num: {raw_train_set_stat[0]}, num_classes: {raw_train_set_stat[1]}, class_sample_num: {raw_train_set_stat[2]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Trial 0, set seed as 7 ----------\n",
      "38400, 9600, 12000: 60000\n",
      "[25170 10935 43596 13970 24883  7581  1712  3004 12834 50176]\n",
      "Statistic info of request set: (12000, 10, [1227, 1346, 1200, 1162, 1188, 1081, 1199, 1219, 1183, 1195])\n",
      "\n",
      "---------- Trial 1, set seed as 8 ----------\n",
      "38400, 9600, 12000: 60000\n",
      "[32997 56059 13395 50681 27244 38348 38157  2062 27732 21545]\n",
      "Statistic info of request set: (12000, 10, [1196, 1349, 1206, 1203, 1180, 1039, 1240, 1244, 1189, 1154])\n",
      "\n",
      "---------- Trial 2, set seed as 9 ----------\n",
      "38400, 9600, 12000: 60000\n",
      "[13131 14170 37932 50105 40269 11929 52723 58524 46502 42902]\n",
      "Statistic info of request set: (12000, 10, [1186, 1312, 1204, 1185, 1170, 1125, 1205, 1281, 1156, 1176])\n",
      "\n",
      "---------- Trial 3, set seed as 10 ----------\n",
      "38400, 9600, 12000: 60000\n",
      "[ 4883 28477  8527 38347  3363 36370  6083 34418 18938 17773]\n",
      "Statistic info of request set: (12000, 10, [1207, 1399, 1149, 1170, 1194, 1036, 1171, 1248, 1214, 1212])\n",
      "\n",
      "---------- Trial 4, set seed as 11 ----------\n",
      "38400, 9600, 12000: 60000\n",
      "[17110 52027 54904 11983 58999 35787 20290 43990 20221 18454]\n",
      "Statistic info of request set: (12000, 10, [1204, 1313, 1220, 1278, 1194, 1054, 1141, 1279, 1205, 1112])\n"
     ]
    }
   ],
   "source": [
    "for trial in range(trials):\n",
    "    print(f'\\n{\"-\"*10} Trial {trial}, set seed as {seed+trial} {\"-\"*10}')\n",
    "    set_seed(seed + trial)\n",
    "\n",
    "    train_set = copy.deepcopy(raw_train_set)\n",
    "    test_set = copy.deepcopy(raw_test_set)\n",
    "\n",
    "    shuffled_idx = np.arange(len(train_set))\n",
    "    np.random.shuffle(shuffled_idx)\n",
    "    split_at = int(len(train_set) * (1 - request_rate))\n",
    "    train_idx, request_idx = shuffled_idx[:split_at], shuffled_idx[split_at:]\n",
    "\n",
    "    val_at = int(len(train_idx) * (1 - val_rate))\n",
    "    val_idx = train_idx[val_at:]\n",
    "    train_idx = train_idx[:val_at]\n",
    "    print(f'{len(train_idx)}, {len(val_idx)}, {len(request_idx)}: {len(train_idx) + len(val_idx) + len(request_idx)}')\n",
    "    print(train_idx[:10])\n",
    "\n",
    "    # save indexs\n",
    "    save_path = prepared_data_save_path_template % (dataset_name, trial)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    np.save(os.path.join(save_path, 'train_idx.npy'), train_idx)\n",
    "    np.save(os.path.join(save_path, 'val_idx.npy'), val_idx)\n",
    "    np.save(os.path.join(save_path, 'request_idx.npy'), request_idx)\n",
    "\n",
    "    request_set = get_subset(train_set, request_idx)\n",
    "    print(f'Statistic info of request set: {statstic_info(request_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tryal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
